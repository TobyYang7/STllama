{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                id  \\\n",
      "0  train_NYCmulti_region_0_1_len_0   \n",
      "1  train_NYCmulti_region_1_2_len_0   \n",
      "2  train_NYCmulti_region_2_3_len_0   \n",
      "3  train_NYCmulti_region_3_4_len_0   \n",
      "4  train_NYCmulti_region_4_5_len_0   \n",
      "\n",
      "                                       conversations  \n",
      "0  [{'from': 'human', 'value': 'Given the histori...  \n",
      "1  [{'from': 'human', 'value': 'Given the histori...  \n",
      "2  [{'from': 'human', 'value': 'Given the histori...  \n",
      "3  [{'from': 'human', 'value': 'Given the histori...  \n",
      "4  [{'from': 'human', 'value': 'Given the histori...  \n",
      "(863040, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_json = pd.read_json(\"data/train_data/multi_NYC.json\")\n",
    "df_pkl = pd.read_pickle(\"data/train_data/multi_NYC_pkl.pkl\")\n",
    "print(df_json.head())\n",
    "print(df_json.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "len(df_pkl)  # 10788\n",
    "print(type(df_pkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12, 80, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pkl[0]['data_x'].shape  # (1,12,80,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given the historical data for crime over 12 time steps in a specific region of New York City, the recorded number of robberies is [0 0 0 1 0 1 0 0 0 0 1 0], and the recorded number of assaults is [0 0 0 2 1 0 0 0 0 0 0 0]. The recording time of the historical data is 'November 14, 2018, 00:00, Wednesday to November 25, 2018, 00:00, Sunday, with data points recorded at 1-day intervals'. Here is the region information: This region is located within the Staten Island borough district and encompasses various POIs within a one-kilometer radius, covering Education Facility, Recreational Facility, Cultural Facility, Residential categories. Now we aim to predict whether the two specific crimes will occur in this region within the next 12 time steps during the time period of 'November 26, 2018, 00:00, Monday to December 7, 2018, 00:00, Friday, with data points recorded at 1-day intervals'. To improve prediction accuracy, a spatio-temporal model is utilized to encode the historical crime data as tokens <ST_HIS>, where the first and the second tokens correspond to the representations of robberies and assaults. Please conduct an analysis of the crime patterns in this region, considering the provided time and regional information, and then generate the prediction tokens for classification, in the form \"<ST_PRE>\".\n"
     ]
    }
   ],
   "source": [
    "print(df_json['conversations'][0][0]['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the historical data for crime over 12 time steps in a specific region of New York City, the recorded number of robberies is [0 0 0 1 0 1 0 0 0 0 1 0], and the recorded number of assaults is [0 0 0 2 1 0 0 0 0 0 0 0]. The recording time of the historical data is 'November 14, 2018, 00:00, Wednesday to November 25, 2018, 00:00, Sunday, with data points recorded at 1-day intervals'. Here is the region information: This region is located within the Staten Island borough district and encompasses various POIs within a one-kilometer radius, covering Education Facility, Recreational Facility, Cultural Facility, Residential categories. Now we aim to predict whether the two specific crimes will occur in this region within the next 12 time steps during the time period of 'November 26, 2018, 00:00, Monday to December 7, 2018, 00:00, Friday, with data points recorded at 1-day intervals'. To improve prediction accuracy, a spatio-temporal model is utilized to encode the historical crime data as tokens <ST_HIS>, where the first and the second tokens correspond to the representations of robberies and assaults. Please conduct an analysis of the crime patterns in this region, considering the provided time and regional information, and then generate the prediction tokens for classification, in the form \"<ST_PRE>\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 \n",
      "0.0 1.0 1.0 0.0 0.0 0.0 0.0 2.0 1.0 0.0 1.0 0.0 "
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "F = 0\n",
    "\n",
    "for i in range(12):\n",
    "    print(df_pkl[0]['data_x'][0, i, idx, F], end=' ')\n",
    "\n",
    "print()  # 添加一个新行以分隔两个循环的输出\n",
    "\n",
    "for i in range(12):\n",
    "    print(df_pkl[0]['data_y'][0, i, idx, F], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# df_json_sample = df_json[:80]\n",
    "# df_json_sample.to_json(\"data/train_data/multi_NYC_sample.json\")\n",
    "# df_pkl_sample = df_pkl[:1]\n",
    "# with open('data/train_data/multi_NYC_pkl_sample.pkl', 'wb') as f:\n",
    "#     pickle.dump(df_pkl_sample, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'from': 'human', 'value': 'Given the historical data for taxi flow over 12 time steps in a specific region of New York City, the recorded taxi inflows are [0 4 2 2 1 1 1 2 2 1 0 2], and the recorded taxi outflows are [0 2 0 0 0 0 0 0 0 0 0 0]. The recording time of the historical data is \\'January 26, 2017, 21:00, Thursday to January 27, 2017, 02:30, Friday, with data points recorded at 30-minute intervals\\'. Here is the region information: No description is available for this region. Now we want to predict the taxi inflow and outflow for the next 12 time steps during the time period of \\'January 27, 2017, 03:00, Friday to January 27, 2017, 08:30, Friday, with data points recorded at 30-minute intervals\\'. To improve prediction accuracy, a spatio-temporal model is utilized to encode the historical taxi data as tokens <ST_HIS>, where the first and the second tokens correspond to the representations of taxi inflow and outflow. Please conduct an analysis of the traffic patterns in this region, taking into account the provided time and regional information, and then generate the predictive tokens for regression, in the form \"<ST_PRE>\".'}, {'from': 'gpt', 'value': 'Based on the given information, the predictive tokens of taxi inflow and outflow in this region are <ST_PRE>.'}]\n"
     ]
    }
   ],
   "source": [
    "# print(df_json['id'])\n",
    "print(df_json['conversations'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   id  \\\n",
      "0     train_NYCmulti_region_0_1_len_0   \n",
      "1     train_NYCmulti_region_1_2_len_0   \n",
      "2     train_NYCmulti_region_2_3_len_0   \n",
      "3     train_NYCmulti_region_3_4_len_0   \n",
      "4     train_NYCmulti_region_4_5_len_0   \n",
      "..                                ...   \n",
      "75  train_NYCmulti_region_75_76_len_0   \n",
      "76  train_NYCmulti_region_76_77_len_0   \n",
      "77  train_NYCmulti_region_77_78_len_0   \n",
      "78  train_NYCmulti_region_78_79_len_0   \n",
      "79  train_NYCmulti_region_79_80_len_0   \n",
      "\n",
      "                                        conversations  \n",
      "0   [{'from': 'human', 'value': 'Given the histori...  \n",
      "1   [{'from': 'human', 'value': 'Given the histori...  \n",
      "2   [{'from': 'human', 'value': 'Given the histori...  \n",
      "3   [{'from': 'human', 'value': 'Given the histori...  \n",
      "4   [{'from': 'human', 'value': 'Given the histori...  \n",
      "..                                                ...  \n",
      "75  [{'from': 'human', 'value': 'Given the histori...  \n",
      "76  [{'from': 'human', 'value': 'Given the histori...  \n",
      "77  [{'from': 'human', 'value': 'Given the histori...  \n",
      "78  [{'from': 'human', 'value': 'Given the histori...  \n",
      "79  [{'from': 'human', 'value': 'Given the histori...  \n",
      "\n",
      "[80 rows x 2 columns]\n",
      "[{'data_x': array([[[[0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [1., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[1., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 1., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 5., 4.],\n",
      "         [0., 0., 4.]]]]), 'data_y': array([[[[0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[1., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[1., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [2., 1., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[1., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [1., 0., 4.],\n",
      "         [0., 0., 4.]],\n",
      "\n",
      "        [[0., 1., 4.],\n",
      "         [0., 0., 4.],\n",
      "         [0., 0., 4.],\n",
      "         ...,\n",
      "         [0., 0., 4.],\n",
      "         [1., 2., 4.],\n",
      "         [0., 0., 4.]]]])}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_json = pd.read_json(\"data/train_data/multi_NYC_sample.json\")\n",
    "df_pkl = pd.read_pickle(\"data/train_data/multi_NYC_pkl_sample.pkl\")\n",
    "print(df_json)\n",
    "print(df_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_pkl\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m79\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_x\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m df_pkl[\u001b[38;5;241m79\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_y\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df_pkl[79]['data_x'] == df_pkl[79]['data_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
